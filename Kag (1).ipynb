{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting options\n",
    "mpl.style.use('ggplot')\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv(r'C:\\Users\\Alvi Mahmud\\Desktop\\BAN Sp20\\Kag\\train.csv')\n",
    "df_test=pd.read_csv(r'C:\\Users\\Alvi Mahmud\\Desktop\\BAN Sp20\\Kag\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600000 entries, 0 to 599999\n",
      "Data columns (total 25 columns):\n",
      "id        600000 non-null int64\n",
      "bin_0     582106 non-null float64\n",
      "bin_1     581997 non-null float64\n",
      "bin_2     582070 non-null float64\n",
      "bin_3     581986 non-null object\n",
      "bin_4     581953 non-null object\n",
      "nom_0     581748 non-null object\n",
      "nom_1     581844 non-null object\n",
      "nom_2     581965 non-null object\n",
      "nom_3     581879 non-null object\n",
      "nom_4     581965 non-null object\n",
      "nom_5     582222 non-null object\n",
      "nom_6     581869 non-null object\n",
      "nom_7     581997 non-null object\n",
      "nom_8     582245 non-null object\n",
      "nom_9     581927 non-null object\n",
      "ord_0     581712 non-null float64\n",
      "ord_1     581959 non-null object\n",
      "ord_2     581925 non-null object\n",
      "ord_3     582084 non-null object\n",
      "ord_4     582070 non-null object\n",
      "ord_5     582287 non-null object\n",
      "day       582048 non-null float64\n",
      "month     582012 non-null float64\n",
      "target    600000 non-null int64\n",
      "dtypes: float64(6), int64(2), object(17)\n",
      "memory usage: 114.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Data columns (total 24 columns):\n",
      "id       400000 non-null int64\n",
      "bin_0    388099 non-null float64\n",
      "bin_1    387962 non-null float64\n",
      "bin_2    388028 non-null float64\n",
      "bin_3    388049 non-null object\n",
      "bin_4    388049 non-null object\n",
      "nom_0    387938 non-null object\n",
      "nom_1    388053 non-null object\n",
      "nom_2    387821 non-null object\n",
      "nom_3    387824 non-null object\n",
      "nom_4    388007 non-null object\n",
      "nom_5    388088 non-null object\n",
      "nom_6    387988 non-null object\n",
      "nom_7    387997 non-null object\n",
      "nom_8    388044 non-null object\n",
      "nom_9    387940 non-null object\n",
      "ord_0    388107 non-null float64\n",
      "ord_1    387833 non-null object\n",
      "ord_2    387895 non-null object\n",
      "ord_3    387947 non-null object\n",
      "ord_4    388067 non-null object\n",
      "ord_5    387953 non-null object\n",
      "day      387975 non-null float64\n",
      "month    388016 non-null float64\n",
      "dtypes: float64(6), int64(1), object(17)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1',\n",
      "       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n",
      "       'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day', 'month',\n",
      "       'target'],\n",
      "      dtype='object')\n",
      "   id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2   nom_3  ...  \\\n",
      "0   0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster  Russia  ...   \n",
      "1   1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl     NaN  ...   \n",
      "2   2    0.0    1.0    0.0     F     N   Red        NaN  Hamster  Canada  ...   \n",
      "\n",
      "       nom_9 ord_0        ord_1     ord_2 ord_3 ord_4  ord_5  day month target  \n",
      "0  02e7c8990   3.0  Contributor       Hot     c     U     Pw  6.0   3.0      0  \n",
      "1  f37df64af   3.0  Grandmaster      Warm     e     X     pE  7.0   7.0      0  \n",
      "2        NaN   3.0          NaN  Freezing     n     P     eN  5.0   9.0      0  \n",
      "\n",
      "[3 rows x 25 columns]\n",
      "       id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0    nom_1    nom_2    nom_3  \\\n",
      "0  600000    0.0    0.0    0.0     F     Y  Blue  Polygon  Axolotl  Finland   \n",
      "1  600001    0.0    0.0    0.0     F     Y   Red   Circle     Lion   Russia   \n",
      "2  600002    0.0    0.0    0.0     F     Y  Blue   Circle  Axolotl   Russia   \n",
      "\n",
      "   ...      nom_8      nom_9 ord_0   ord_1        ord_2 ord_3  ord_4 ord_5  \\\n",
      "0  ...  ca9ad1d4b  fced9e114   3.0  Novice  Boiling Hot     f      U    oU   \n",
      "1  ...  060a21580  7ca8775da   1.0  Novice         Cold     n      N   NaN   \n",
      "2  ...  165e81a00  5940334c9   1.0  Expert         Warm     i      N    DN   \n",
      "\n",
      "   day month  \n",
      "0  3.0   9.0  \n",
      "1  2.0   8.0  \n",
      "2  2.0   6.0  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "print(df_train.head(3))\n",
    "print(df_test.head(3))\n",
    "\n",
    "#Mask the Null values to retain them during encoding\n",
    "mask_train= df_train.isin(['nan'])\n",
    "mask_test= df_test.isin(['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert object to string\n",
    "df_train[['bin_3','bin_4','nom_0', 'nom_1',\n",
    "       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']]= df_train[['bin_3','bin_4','nom_0', 'nom_1',\n",
    "       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']].astype('str')\n",
    "\n",
    "df_test[['bin_3','bin_4','nom_0', 'nom_1',\n",
    "       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']]= df_test[['bin_3','bin_4','nom_0', 'nom_1',\n",
    "       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode all the nominal features and the two string binary feature\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "df_train_enc= MultiColumnLabelEncoder(columns = [ 'bin_3','bin_4','nom_0', 'nom_1',\n",
    "       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']).fit_transform(df_train)\n",
    "df_train_enc=pd.DataFrame(df_train_enc.where(~mask_train, other=np.nan))\n",
    "\n",
    "df_test_enc= MultiColumnLabelEncoder(columns = [ 'bin_3','bin_4','nom_0', 'nom_1',\n",
    "       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']).fit_transform(df_test)\n",
    "df_test_enc=pd.DataFrame(df_test_enc.where(~mask_test, other=np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    312344\n",
       "1    269609\n",
       "2     18047\n",
       "Name: bin_4, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_enc.bin_4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map low cardinality ordinal features\n",
    "map_ord1 = {'Novice':1, \n",
    "            'Contributor':2, \n",
    "            'Expert':3, \n",
    "            'Master':4, \n",
    "            'Grandmaster':5}\n",
    "df_train_enc.ord_1 = df_train_enc.ord_1.replace(map_ord1)\n",
    "df_test_enc.ord_1 = df_test_enc.ord_1.replace(map_ord1)\n",
    "\n",
    "map_ord2 = {'Freezing':1, \n",
    "            'Cold':10, \n",
    "            'Warm':25, \n",
    "            'Hot':50, \n",
    "            'Boiling Hot':100, \n",
    "            'Lava Hot':800}\n",
    "df_train_enc.ord_2 = df_train_enc.ord_2.replace(map_ord2)\n",
    "df_test_enc.ord_2 = df_test_enc.ord_2.replace(map_ord2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode high cardinality features\n",
    "map_ord3 = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':6, 'g':7, 'h':8, 'i':9, 'j':10, 'k':11, 'l':12,'m':13,'n':14, 'o':15}\n",
    "df_train_enc.ord_3 = df_train_enc.ord_3.replace(map_ord3)\n",
    "df_test_enc.ord_3 = df_test_enc.ord_3.replace(map_ord3)\n",
    "\n",
    "map_ord4 = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'H':8, 'I':9, 'J':10, 'K':11, 'L':12,'M':13,'N':14, 'O':15,\n",
    "           'P':16, 'Q':17, 'R':18, 'S':19, 'T':20, 'U':21, 'V':22, 'W':23, 'X':24, 'Y':25, 'Z':26}\n",
    "df_train_enc.ord_4 = df_train_enc.ord_4.replace(map_ord4)\n",
    "df_test_enc.ord_4 = df_test_enc.ord_4.replace(map_ord4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fl    10562\n",
       "DN     9527\n",
       "Sz     8654\n",
       "RV     5648\n",
       "oJ     5596\n",
       "      ...  \n",
       "vw      189\n",
       "gV      124\n",
       "vQ      120\n",
       "eA       91\n",
       "Zv       87\n",
       "Name: ord_5_enc, Length: 190, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "df_train_enc['ord_5_enc']=df_train_enc['ord_5']\n",
    "df_test_enc['ord_5_enc']=df_test_enc['ord_5']\n",
    "ce_ord = ce.OrdinalEncoder(cols = ['ord_5'])\n",
    "df_train_encall=ce_ord.fit_transform(df_train_enc, df_train_enc['ord_5_enc'])\n",
    "df_test_encall=ce_ord.fit_transform(df_test_enc, df_test_enc['ord_5_enc'])\n",
    "df_train_encall.ord_5_enc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encall.ord_5.value_counts()\n",
    "df_train_encoded= df_train_encall.drop(['target','ord_5_enc'], axis=1)\n",
    "df_test_encoded= df_test_encall.drop('ord_5_enc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  bin_0  bin_1  bin_2  bin_3  bin_4  nom_0  nom_1  nom_2  nom_3  ...  \\\n",
      "0   0    0.0    0.0    0.0      0      0      2      4      3      5  ...   \n",
      "1   1    1.0    1.0    0.0      0      1      2      3      0      6  ...   \n",
      "2   2    0.0    1.0    0.0      0      0      2      6      3      0  ...   \n",
      "\n",
      "   nom_8  nom_9  ord_0  ord_1  ord_2  ord_3  ord_4  ord_5  day  month  \n",
      "0      1     27    3.0    2.0   50.0    3.0   21.0      1  6.0    3.0  \n",
      "1     69   2112    3.0    5.0   25.0    5.0   24.0      2  7.0    7.0  \n",
      "2    102   2218    3.0    NaN    1.0   14.0   16.0      3  5.0    9.0  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600000 entries, 0 to 599999\n",
      "Data columns (total 24 columns):\n",
      "id       600000 non-null int64\n",
      "bin_0    582106 non-null float64\n",
      "bin_1    581997 non-null float64\n",
      "bin_2    582070 non-null float64\n",
      "bin_3    600000 non-null int32\n",
      "bin_4    600000 non-null int32\n",
      "nom_0    600000 non-null int32\n",
      "nom_1    600000 non-null int32\n",
      "nom_2    600000 non-null int32\n",
      "nom_3    600000 non-null int32\n",
      "nom_4    600000 non-null int32\n",
      "nom_5    600000 non-null int32\n",
      "nom_6    600000 non-null int32\n",
      "nom_7    600000 non-null int32\n",
      "nom_8    600000 non-null int32\n",
      "nom_9    600000 non-null int32\n",
      "ord_0    581712 non-null float64\n",
      "ord_1    581959 non-null float64\n",
      "ord_2    581925 non-null float64\n",
      "ord_3    582084 non-null float64\n",
      "ord_4    582070 non-null float64\n",
      "ord_5    600000 non-null int32\n",
      "day      582048 non-null float64\n",
      "month    582012 non-null float64\n",
      "dtypes: float64(10), int32(13), int64(1)\n",
      "memory usage: 80.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_encoded.columns\n",
    "print(df_train_encoded.head(3))\n",
    "df_train_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent') #for median imputation replace 'mean' with 'median'\n",
    "imp_mean.fit(df_train_encoded)\n",
    "df_train_imputed=pd.DataFrame(imp_mean.transform(df_train_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean2 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_mean2.fit(df_test_encoded)\n",
    "df_test_imputed=pd.DataFrame(imp_mean2.transform(df_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0    1    2    3    4    5    6    7    8    9   ...     14      15   16  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  4.0  3.0  5.0  ...    1.0    27.0  3.0   \n",
      "1  1.0  1.0  1.0  0.0  0.0  1.0  2.0  3.0  0.0  6.0  ...   69.0  2112.0  3.0   \n",
      "2  2.0  0.0  1.0  0.0  0.0  0.0  2.0  6.0  3.0  0.0  ...  102.0  2218.0  3.0   \n",
      "\n",
      "    17    18    19    20   21   22   23  \n",
      "0  2.0  50.0   3.0  21.0  1.0  6.0  3.0  \n",
      "1  5.0  25.0   5.0  24.0  2.0  7.0  7.0  \n",
      "2  1.0   1.0  14.0  16.0  3.0  5.0  9.0  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "         0    1    2    3    4    5    6    7    8    9   ...     14      15  \\\n",
      "0  600000.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  3.0  ...  174.0  2194.0   \n",
      "1  600001.0  0.0  0.0  0.0  0.0  1.0  2.0  0.0  4.0  5.0  ...    4.0  1105.0   \n",
      "2  600002.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  5.0  ...   16.0   810.0   \n",
      "\n",
      "    16   17     18    19    20    21   22   23  \n",
      "0  3.0  1.0  100.0   6.0  21.0  49.0  3.0  9.0  \n",
      "1  1.0  1.0   10.0  14.0  14.0   4.0  2.0  8.0  \n",
      "2  1.0  3.0   25.0   9.0  14.0  38.0  2.0  6.0  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train_imputed.head(3))\n",
    "print(df_test_imputed.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    244092\n",
       "1.0    143957\n",
       "2.0     11951\n",
       "Name: bin_3, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_imputed.columns=df_train_encoded.columns\n",
    "df_test_imputed.columns=df_test_encoded.columns\n",
    "\n",
    "df_test_imputed.bin_3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       float64\n",
      "bin_0    float64\n",
      "bin_1    float64\n",
      "bin_2    float64\n",
      "bin_3    float64\n",
      "bin_4    float64\n",
      "nom_0    float64\n",
      "nom_1    float64\n",
      "nom_2    float64\n",
      "nom_3    float64\n",
      "nom_4    float64\n",
      "nom_5    float64\n",
      "nom_6    float64\n",
      "nom_7    float64\n",
      "nom_8    float64\n",
      "nom_9    float64\n",
      "ord_0    float64\n",
      "ord_1    float64\n",
      "ord_2    float64\n",
      "ord_3    float64\n",
      "ord_4    float64\n",
      "ord_5    float64\n",
      "day      float64\n",
      "month    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train_imputed.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       float64\n",
      "bin_0    float64\n",
      "bin_1    float64\n",
      "bin_2    float64\n",
      "bin_3    float64\n",
      "bin_4    float64\n",
      "nom_0    float64\n",
      "nom_1    float64\n",
      "nom_2    float64\n",
      "nom_3    float64\n",
      "nom_4    float64\n",
      "nom_5    float64\n",
      "nom_6    float64\n",
      "nom_7    float64\n",
      "nom_8    float64\n",
      "nom_9    float64\n",
      "ord_0    float64\n",
      "ord_1    float64\n",
      "ord_2    float64\n",
      "ord_3    float64\n",
      "ord_4    float64\n",
      "ord_5    float64\n",
      "day      float64\n",
      "month    float64\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_test_imputed.dtypes)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.get_dummies(df_train_imputed,columns = [ 'bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1',\n",
    "       'nom_2', 'nom_3', 'nom_4', 'ord_0', 'ord_1', 'ord_2'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600000, 54)\n",
      "Index(['id', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_3', 'ord_4',\n",
      "       'ord_5', 'day', 'month', 'bin_0_1.0', 'bin_1_1.0', 'bin_2_1.0',\n",
      "       'bin_3_1.0', 'bin_3_2.0', 'bin_4_1.0', 'bin_4_2.0', 'nom_0_1.0',\n",
      "       'nom_0_2.0', 'nom_0_3.0', 'nom_1_1.0', 'nom_1_2.0', 'nom_1_3.0',\n",
      "       'nom_1_4.0', 'nom_1_5.0', 'nom_1_6.0', 'nom_2_1.0', 'nom_2_2.0',\n",
      "       'nom_2_3.0', 'nom_2_4.0', 'nom_2_5.0', 'nom_2_6.0', 'nom_3_1.0',\n",
      "       'nom_3_2.0', 'nom_3_3.0', 'nom_3_4.0', 'nom_3_5.0', 'nom_3_6.0',\n",
      "       'nom_4_1.0', 'nom_4_2.0', 'nom_4_3.0', 'nom_4_4.0', 'ord_0_2.0',\n",
      "       'ord_0_3.0', 'ord_1_2.0', 'ord_1_3.0', 'ord_1_4.0', 'ord_1_5.0',\n",
      "       'ord_2_10.0', 'ord_2_25.0', 'ord_2_50.0', 'ord_2_100.0', 'ord_2_800.0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.get_dummies(df_test_imputed,columns = [ 'bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1',\n",
    "       'nom_2', 'nom_3', 'nom_4', 'ord_0', 'ord_1', 'ord_2'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 54)\n",
      "Index(['id', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_3', 'ord_4',\n",
      "       'ord_5', 'day', 'month', 'bin_0_1.0', 'bin_1_1.0', 'bin_2_1.0',\n",
      "       'bin_3_1.0', 'bin_3_2.0', 'bin_4_1.0', 'bin_4_2.0', 'nom_0_1.0',\n",
      "       'nom_0_2.0', 'nom_0_3.0', 'nom_1_1.0', 'nom_1_2.0', 'nom_1_3.0',\n",
      "       'nom_1_4.0', 'nom_1_5.0', 'nom_1_6.0', 'nom_2_1.0', 'nom_2_2.0',\n",
      "       'nom_2_3.0', 'nom_2_4.0', 'nom_2_5.0', 'nom_2_6.0', 'nom_3_1.0',\n",
      "       'nom_3_2.0', 'nom_3_3.0', 'nom_3_4.0', 'nom_3_5.0', 'nom_3_6.0',\n",
      "       'nom_4_1.0', 'nom_4_2.0', 'nom_4_3.0', 'nom_4_4.0', 'ord_0_2.0',\n",
      "       'ord_0_3.0', 'ord_1_2.0', 'ord_1_3.0', 'ord_1_4.0', 'ord_1_5.0',\n",
      "       'ord_2_10.0', 'ord_2_25.0', 'ord_2_50.0', 'ord_2_100.0', 'ord_2_800.0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop('id', axis=1)\n",
    "test=test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(train.values, label=df_train_encall.target.values)\n",
    "dtest = xgb.DMatrix(test.values)\n",
    "\n",
    "param = {'max_depth':30, 'silent':1, 'objective':'binary:logistic', 'subsample':0.5,\"booster\": 'dart', \n",
    "         'eval_metric':[\"error\",\"logloss\"],'learning_rate': 0.3, 'seed':420}\n",
    "\n",
    "model= xgb.train(dtrain=dtrain,params= param,num_boost_round=150 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= pd.concat([pd.Series(y_pred), df_test.id],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0      id\n",
      "0       0.072933  600000\n",
      "1       0.020833  600001\n",
      "2       0.036178  600002\n",
      "3       0.238292  600003\n",
      "4       0.174682  600004\n",
      "...          ...     ...\n",
      "399995  0.247446  999995\n",
      "399996  0.043811  999996\n",
      "399997  0.132726  999997\n",
      "399998  0.039880  999998\n",
      "399999  0.020423  999999\n",
      "\n",
      "[400000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
